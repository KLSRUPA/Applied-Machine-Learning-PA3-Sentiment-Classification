{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This implementation uses a python library called the autocorrect to correct the spellings."
      ],
      "metadata": {
        "id": "X-U4HkCrye1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFlmhfDTZ4HI",
        "outputId": "173359e9-c5b0-4674-a535-b45beabfbb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.10/dist-packages (2.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries"
      ],
      "metadata": {
        "id": "XOcmtS9uynhP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1br4WvQADbWM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from autocorrect import Speller\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ignore unwanted warnings that make cell outputs noisy"
      ],
      "metadata": {
        "id": "R-eLz5XLyxVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "FrDEW_Z9tclz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using pandas to read the csv files"
      ],
      "metadata": {
        "id": "8z8UfY-qyw15"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wVN4TJJFM86"
      },
      "outputs": [],
      "source": [
        "crowd_sourced_data = pd.read_csv('/content/crowdsourced_train.csv',sep='\\t')\n",
        "\n",
        "\n",
        "gold_train_data = pd.read_csv('/content/gold_train.csv',sep='\\t')\n",
        "\n",
        "\n",
        "test_data = pd.read_csv('test.csv',sep='\\t')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Creating a pipeline to construct a pipeline for easier implementation\n",
        "*   Implementing TfidVectorizer and LinearSVC into a pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "eyd17ESxy6f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline( TfidfVectorizer(), LinearSVC(dual=False) )"
      ],
      "metadata": {
        "id": "5Y_AJJAifkPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Copying the original dataset to create a new dataset for correcting spellings\n",
        "*  Using \"Speller\" module of \"autocorrect\" and setting \"lang\" as \"en\"\n",
        "\n",
        "*   Reference: [https://github.com/filyp/autocorrect]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6YwkZZzYzJCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = crowd_sourced_data['sentiment'].tolist()\n",
        "corrected_CSdata = crowd_sourced_data.copy()\n",
        "\n",
        "spell_correction = Speller(lang='en')"
      ],
      "metadata": {
        "id": "uMMhchWrtzor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a function that corrects the sentiment terms into their right spellings"
      ],
      "metadata": {
        "id": "x1B1KMmnzXNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_spelling(term):\n",
        "    term = term.strip()\n",
        "    if term.lower() == 'neutral l':\n",
        "      return 'neutral'\n",
        "    elif term.lower() in ['positive', 'neutral', 'negative']:\n",
        "      return term.lower()\n",
        "    else:\n",
        "      return spell_correction(term)\n",
        "\n",
        "corrected_CSdata['sentiment'] = corrected_CSdata['sentiment'].apply(correct_spelling)"
      ],
      "metadata": {
        "id": "1h6iPF04wq8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a function to implement hyper-parameter tuning, fitting datasets, prediction using test.csv, and calculating classification report and accuracy score"
      ],
      "metadata": {
        "id": "vfjJsm1Wzbao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def implementation(data, test):\n",
        "\n",
        "  param_grid = {\n",
        "    'tfidfvectorizer__max_features': [1000, 5000, 10000],\n",
        "    'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "    'linearsvc__C': [0.1, 1, 100]\n",
        "  }\n",
        "\n",
        "  grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "  grid_search.fit(data['text'], data['sentiment'])\n",
        "\n",
        "  best_model = grid_search.best_estimator_\n",
        "\n",
        "  predict = best_model.predict(test_data['text'])\n",
        "\n",
        "  print(f\"Classification report for given data is:\")\n",
        "  print(classification_report(test['sentiment'], predict))\n",
        "  print(\"Accuracy:\",accuracy_score(test['sentiment'], predict))"
      ],
      "metadata": {
        "id": "ZEPScqvGU8Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing the above implementation() for the dataset \"crowd_sourced_data\""
      ],
      "metadata": {
        "id": "seZWXUzmzf1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "implementation(crowd_sourced_data,test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLkIhKBtVmFa",
        "outputId": "e8e0bb38-4db2-46d7-fee9-102acca2edec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for given data is:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00         0\n",
            "     Neutral       0.00      0.00      0.00         0\n",
            "    Positive       0.00      0.00      0.00         0\n",
            "    negative       0.52      0.31      0.39      1077\n",
            "     neutral       0.59      0.46      0.52      2597\n",
            "    positive       0.71      0.33      0.45      1850\n",
            "\n",
            "    accuracy                           0.39      5524\n",
            "   macro avg       0.30      0.18      0.23      5524\n",
            "weighted avg       0.62      0.39      0.47      5524\n",
            "\n",
            "Accuracy: 0.38848660391021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing the above implementation() for the dataset \"gold_train_data\""
      ],
      "metadata": {
        "id": "8CqfSeWpzlvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "implementation(gold_train_data,test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2ulZ8g4WmiU",
        "outputId": "0f731564-3dc2-480b-dd2f-026225831f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for given data is:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.29      0.42      1077\n",
            "     neutral       0.62      0.86      0.72      2597\n",
            "    positive       0.74      0.61      0.67      1850\n",
            "\n",
            "    accuracy                           0.67      5524\n",
            "   macro avg       0.71      0.59      0.60      5524\n",
            "weighted avg       0.69      0.67      0.65      5524\n",
            "\n",
            "Accuracy: 0.6660028964518465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing the above implementation() for the dataset \"correctedCS_data\". \"correctedCS_data\" is the dataset that is created after crowd_sourced_data is preprocessed."
      ],
      "metadata": {
        "id": "QJkXPdQUzsk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "implementation(corrected_CSdata,test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZkIEB28WmU3",
        "outputId": "d844093f-2102-4f8b-92c7-0dcd7e9773c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for given data is:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.59      0.40      0.47      1077\n",
            "     neutral       0.59      0.82      0.69      2597\n",
            "    positive       0.74      0.47      0.57      1850\n",
            "\n",
            "    accuracy                           0.62      5524\n",
            "   macro avg       0.64      0.56      0.58      5524\n",
            "weighted avg       0.64      0.62      0.61      5524\n",
            "\n",
            "Accuracy: 0.6205648081100652\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}